#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¼‚æ„å›¾ç¥ç»ç½‘ç»œæ¨¡å‹ - PyTorch Geometricç‰ˆæœ¬
åŸºäºå¼‚æ„è¾¹ç±»å‹çš„æ”¹è¿›LIVABLEæ¶æ„ï¼Œä½¿ç”¨PyGå®ç°
"""

import json
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import numpy as np
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix
import logging
from pathlib import Path
from tqdm import tqdm
import copy
from typing import Dict, List, Optional

# PyG Imports
try:
    from torch_geometric.data import Dataset, Data
    from torch_geometric.loader import DataLoader
    from torch_geometric.nn import MessagePassing, global_mean_pool, global_max_pool
    from torch_geometric.utils import add_self_loops, degree
except ImportError:
    print("âŒ PyTorch Geometricä¸å¯ç”¨ï¼Œè¯·å®‰è£… pip install torch-geometric")
    exit(1)

logging.basicConfig(level=logging.INFO, format='[%(asctime)s] INFO: %(message)s', datefmt='%H:%M:%S')
logger = logging.getLogger(__name__)


class HeterogeneousGNNLayer(MessagePassing):
    """
    å¼‚æ„å›¾ç¥ç»ç½‘ç»œå±‚ - PyGå®ç°
    
    å®ç°å…¬å¼: h_i^{(l+1)} = Ïƒ((1-Î±) Î£_{râˆˆR} Î£_{jâˆˆN_i^r} (1/c_{i,r}) W_r^{(l)} h_j^{(l)} + W_0^{(l)} h_i^{(l)} + Î± h_i^{(0)})
    """
    
    def __init__(self,
                 input_dim: int,
                 output_dim: int,
                 num_edge_types: int = 4,
                 alpha: float = 0.1,
                 dropout: float = 0.2,
                 aggr: str = 'add'):
        super(HeterogeneousGNNLayer, self).__init__(aggr=aggr)
        
        self.input_dim = input_dim
        self.output_dim = output_dim
        self.num_edge_types = num_edge_types
        self.alpha = alpha
        
        # ä¸ºæ¯ç§è¾¹ç±»å‹å®šä¹‰ä¸“ç”¨æƒé‡çŸ©é˜µ W_r
        self.edge_type_weights = nn.ModuleList([
            nn.Linear(input_dim, output_dim, bias=False)
            for _ in range(num_edge_types)
        ])
        
        # è‡ªè¿æ¥æƒé‡çŸ©é˜µ W_0
        self.self_weight = nn.Linear(input_dim, output_dim, bias=True)
        
        # è¾“å…¥æŠ•å½±ï¼ˆç”¨äºæ®‹å·®è¿æ¥ï¼‰
        if input_dim != output_dim:
            self.input_projection = nn.Linear(input_dim, output_dim, bias=False)
        else:
            self.input_projection = nn.Identity()
        
        # è¾¹ç±»å‹æ³¨æ„åŠ›æƒé‡
        self.edge_attention = nn.ModuleList([
            nn.Sequential(
                nn.Linear(output_dim * 2, output_dim // 2),
                nn.ReLU(),
                nn.Linear(output_dim // 2, 1),
                nn.LeakyReLU(0.2)
            ) for _ in range(num_edge_types)
        ])
        
        # æ­£åˆ™åŒ–
        self.dropout = nn.Dropout(dropout)
        self.layer_norm = nn.LayerNorm(output_dim)
        
        # è¾¹ç±»å‹åµŒå…¥
        self.edge_type_embeddings = nn.Embedding(num_edge_types, output_dim // 4)
        
        # å±‚çº§åˆ«çš„è¾¹ç±»å‹é‡è¦æ€§æƒé‡
        self.layer_edge_importance = nn.Parameter(torch.ones(num_edge_types))
        
        self.reset_parameters()
    
    def reset_parameters(self):
        """å‚æ•°åˆå§‹åŒ–"""
        gain = nn.init.calculate_gain('relu')
        
        for i in range(self.num_edge_types):
            nn.init.xavier_uniform_(self.edge_type_weights[i].weight, gain=gain)
        
        nn.init.xavier_uniform_(self.self_weight.weight, gain=gain)
        if self.self_weight.bias is not None:
            nn.init.zeros_(self.self_weight.bias)
        
        if hasattr(self.input_projection, 'weight'):
            nn.init.xavier_uniform_(self.input_projection.weight, gain=gain)
        
        nn.init.uniform_(self.edge_type_embeddings.weight, -0.1, 0.1)
        
        # åŸºäºæ¼æ´æ£€æµ‹ç†è®ºåˆå§‹åŒ–è¾¹ç±»å‹é‡è¦æ€§
        with torch.no_grad():
            prior_weights = torch.tensor([1.2, 1.1, 1.4, 0.9])  # AST, CFG, DFG, CDG
            self.layer_edge_importance.data = prior_weights
    
    def forward(self, x: torch.Tensor, edge_index: torch.Tensor, 
                edge_type: Optional[torch.Tensor] = None,
                initial_x: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            x: èŠ‚ç‚¹ç‰¹å¾ [N, input_dim]
            edge_index: è¾¹ç´¢å¼• [2, E] 
            edge_type: è¾¹ç±»å‹ [E] (å¯é€‰ï¼Œé»˜è®¤ä¸º0)
            initial_x: åˆå§‹ç‰¹å¾ï¼ˆç”¨äºæ®‹å·®è¿æ¥ï¼‰[N, output_dim]
            
        Returns:
            æ›´æ–°åçš„èŠ‚ç‚¹ç‰¹å¾ [N, output_dim]
        """
        if initial_x is None:
            initial_x = self.input_projection(x)
        
        if edge_type is None:
            edge_type = torch.zeros(edge_index.size(1), dtype=torch.long, device=x.device)
        
        # è®¡ç®—è¾¹ç±»å‹é‡è¦æ€§æƒé‡
        edge_weights = F.softmax(self.layer_edge_importance, dim=0)
        
        # ä¸ºæ¯ç§è¾¹ç±»å‹åˆ†åˆ«è¿›è¡Œæ¶ˆæ¯ä¼ é€’
        type_messages = []
        
        for r in range(self.num_edge_types):
            # ç­›é€‰å½“å‰è¾¹ç±»å‹çš„è¾¹
            edge_mask = (edge_type == r)
            
            if edge_mask.sum() > 0:
                # è·å–è¯¥ç±»å‹çš„è¾¹
                type_edge_index = edge_index[:, edge_mask]
                
                # åº”ç”¨è¾¹ç±»å‹ç‰¹å®šçš„å˜æ¢
                transformed_x = self.edge_type_weights[r](x)
                
                # æ¶ˆæ¯ä¼ é€’
                messages = self.propagate(
                    type_edge_index, 
                    x=transformed_x, 
                    original_x=x,
                    edge_type_id=r
                )
                
                # åº”ç”¨è¾¹ç±»å‹é‡è¦æ€§æƒé‡
                weighted_messages = messages * edge_weights[r]
                type_messages.append(weighted_messages)
            else:
                # å¦‚æœæ²¡æœ‰è¯¥ç±»å‹çš„è¾¹ï¼Œæ·»åŠ é›¶æ¶ˆæ¯
                type_messages.append(torch.zeros(x.size(0), self.output_dim, device=x.device))
        
        # èšåˆæ‰€æœ‰è¾¹ç±»å‹çš„æ¶ˆæ¯
        aggregated_messages = torch.stack(type_messages, dim=0).sum(dim=0)
        
        # è‡ªè¿æ¥
        self_transformed = self.self_weight(x)
        
        # ç»„åˆ: (1-Î±) * é‚»å±…æ¶ˆæ¯ + è‡ªè¿æ¥ + Î± * åˆå§‹ç‰¹å¾
        output = ((1 - self.alpha) * aggregated_messages + 
                 self_transformed + 
                 self.alpha * initial_x)
        
        # åº”ç”¨dropoutå’Œå±‚å½’ä¸€åŒ–
        output = self.dropout(output)
        output = self.layer_norm(output)
        output = F.gelu(output)
        
        return output
    
    def get_layer_edge_importance(self):
        """è·å–å±‚çº§åˆ«çš„è¾¹ç±»å‹é‡è¦æ€§æƒé‡"""
        return F.softmax(self.layer_edge_importance, dim=0)
    
    def message(self, x_j: torch.Tensor, x_i: torch.Tensor, 
                original_x_j: torch.Tensor, original_x_i: torch.Tensor,
                edge_type_id: int, index: torch.Tensor) -> torch.Tensor:
        """è®¡ç®—æ¶ˆæ¯"""
        # è®¡ç®—æ³¨æ„åŠ›æƒé‡
        concat_features = torch.cat([original_x_i, original_x_j], dim=1)
        attention_scores = self.edge_attention[edge_type_id](concat_features)
        
        # è¾¹ç±»å‹åµŒå…¥å¢å¼º
        edge_emb = self.edge_type_embeddings(
            torch.full((attention_scores.size(0),), edge_type_id, 
                      dtype=torch.long, device=x_j.device)
        )
        enhanced_scores = attention_scores + torch.mean(edge_emb, dim=1, keepdim=True)
        
        # è½¯æ³¨æ„åŠ›
        alpha = F.softmax(enhanced_scores, dim=0)
        
        return alpha * x_j


class MLPReadout(nn.Module):
    """å¤šå±‚æ„ŸçŸ¥æœºè¯»å‡ºå±‚"""
    def __init__(self, input_dim, output_dim, L=2):
        super().__init__()
        layers = []
        dim = input_dim
        
        for l in range(L):
            layers.append(nn.Linear(dim, dim // 2, bias=True))
            layers.append(nn.ReLU())
            layers.append(nn.Dropout(0.1))
            dim = dim // 2
        
        layers.append(nn.Linear(dim, output_dim, bias=True))
        self.layers = nn.Sequential(*layers)
        
    def forward(self, x):
        return self.layers(x)


class HeterogeneousLIVABLEPygModel(nn.Module):
    """åŸºäºPyTorch Geometricçš„å¼‚æ„LIVABLEæ¨¡å‹"""
    
    def __init__(self, 
                 input_dim: int = 768,
                 hidden_dim: int = 256,
                 seq_input_dim: int = 128,
                 num_classes: int = 14,
                 num_edge_types: int = 4,
                 num_gnn_layers: int = 3,
                 alpha: float = 0.15,
                 dropout: float = 0.2,
                 max_seq_len: int = 6):
        super(HeterogeneousLIVABLEPygModel, self).__init__()
        
        self.hidden_dim = hidden_dim
        self.num_gnn_layers = num_gnn_layers
        self.max_seq_len = max_seq_len
        self.seq_hid = 256
        
        # è¾“å…¥æŠ•å½±
        self.input_projection = nn.Linear(input_dim, hidden_dim)
        
        # å¼‚æ„GNNå±‚
        self.hetero_gnn_layers = nn.ModuleList([
            HeterogeneousGNNLayer(
                input_dim=hidden_dim,
                output_dim=hidden_dim,
                num_edge_types=num_edge_types,
                alpha=alpha,
                dropout=dropout
            ) for _ in range(num_gnn_layers)
        ])
        
        # å›¾åˆ†æ”¯MLP
        self.graph_mlp = MLPReadout(hidden_dim, num_classes, L=2)
        
        # åºåˆ—åˆ†æ”¯ - åŒå‘GRU
        self.sequence_gru = nn.GRU(
            seq_input_dim, 
            self.seq_hid, 
            num_layers=1, 
            bidirectional=True, 
            batch_first=True
        )
        
        # åºåˆ—åˆ†æ”¯MLP
        self.sequence_mlp = MLPReadout(2 * self.seq_hid, num_classes, L=2)
        
        # å…¨å±€dropout
        self.dropout = nn.Dropout(dropout)
        
        # å¯å­¦ä¹ çš„è¾¹ç±»å‹é‡è¦æ€§æƒé‡ - å…³é”®æ”¹è¿›
        self.edge_type_importance = nn.Parameter(torch.ones(num_edge_types))
        self._init_edge_importance()
        
    def forward(self, data):
        """å‰å‘ä¼ æ’­"""
        x, edge_index, sequence, batch = data.x, data.edge_index, data.sequence, data.batch
        
        # è·å–è¾¹ç±»å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        edge_type = getattr(data, 'edge_type', None)
        
        # --- åºåˆ—åˆ†æ”¯ ---
        batch_size = data.num_graphs
        # é‡å¡‘åºåˆ—: (B * L, D) -> (B, L, D)
        sequence = sequence.view(batch_size, self.max_seq_len, -1)
        seq_out, _ = self.sequence_gru(sequence)
        
        # åºåˆ—æ± åŒ–
        seq_out = torch.transpose(seq_out, 1, 2)
        seq1 = F.avg_pool1d(seq_out, seq_out.size(2)).squeeze(2)
        seq2 = F.max_pool1d(seq_out, seq_out.size(2)).squeeze(2)
        seq_outputs = self.sequence_mlp(self.dropout(seq1 + seq2))
        
        # --- å¼‚æ„å›¾åˆ†æ”¯ ---
        if x.numel() > 0:
            # è¾“å…¥æŠ•å½±
            h = self.input_projection(x)
            initial_h = h.clone()
            
            # é€šè¿‡å¼‚æ„GNNå±‚
            for i, gnn_layer in enumerate(self.hetero_gnn_layers):
                h = gnn_layer(h, edge_index, edge_type, initial_h)
            
            # å›¾çº§æ± åŒ–
            graph_pooled = global_mean_pool(h, batch)
            graph_outputs = self.graph_mlp(self.dropout(graph_pooled))
        else:
            graph_outputs = torch.zeros_like(seq_outputs)
        
        # ç»„åˆè¾“å‡º
        return graph_outputs + seq_outputs
    
    def _init_edge_importance(self):
        """åŸºäºæ¼æ´æ£€æµ‹é¢†åŸŸçŸ¥è¯†åˆå§‹åŒ–è¾¹ç±»å‹é‡è¦æ€§"""
        with torch.no_grad():
            # AST: è¯­æ³•ç»“æ„, CFG: æ§åˆ¶æµ, DFG: æ•°æ®æµ, CDG: æ§åˆ¶ä¾èµ–
            # åŸºäºç†è®ºï¼ŒDFGå¯¹æ¼æ´æ£€æµ‹æœ€é‡è¦ï¼ŒASTæ¬¡ä¹‹
            prior_weights = torch.tensor([1.2, 1.1, 1.4, 0.9])
            self.edge_type_importance.data = prior_weights
    
    def get_edge_type_importance(self):
        """è·å–è¾¹ç±»å‹é‡è¦æ€§æƒé‡"""
        return F.softmax(self.edge_type_importance, dim=0)


class HeterogeneousPygDataset(Dataset):
    """å¼‚æ„å›¾PyGæ•°æ®é›†"""
    
    def __init__(self, root, data_list, max_seq_len=6):
        self.data_list = data_list
        self.max_seq_len = max_seq_len
        
        # è¾¹ç±»å‹æ˜ å°„
        self.edge_type_mapping = {
            'AST': 0,
            'CFG': 1,
            'DFG': 2,
            'CDG': 3
        }
        
        super(HeterogeneousPygDataset, self).__init__(root)
    
    def len(self):
        return len(self.data_list)
    
    def get(self, idx):
        item = self.data_list[idx]
        
        # èŠ‚ç‚¹ç‰¹å¾
        features = torch.FloatTensor(item['features'])
        num_nodes = features.shape[0]
        
        # è¾¹å’Œè¾¹ç±»å‹
        edges = item['structure']
        sources, dests, edge_types = [], [], []
        
        for s, edge_type_str, t in edges:
            if s < num_nodes and t < num_nodes:
                sources.append(s)
                dests.append(t)
                # æ˜ å°„è¾¹ç±»å‹
                edge_type_id = self.edge_type_mapping.get(edge_type_str, 0)
                edge_types.append(edge_type_id)
        
        edge_index = torch.LongTensor([sources, dests])
        edge_type = torch.LongTensor(edge_types)
        
        # åºåˆ—ç‰¹å¾
        sequence = torch.FloatTensor(item['sequence'])
        if sequence.shape[0] > self.max_seq_len:
            sequence = sequence[:self.max_seq_len, :]
        elif sequence.shape[0] < self.max_seq_len:
            pad_size = self.max_seq_len - sequence.shape[0]
            feat_dim = sequence.shape[1] if sequence.shape[0] > 0 else 128
            padding = torch.zeros(pad_size, feat_dim)
            sequence = torch.cat((sequence, padding), dim=0)
        
        # æ ‡ç­¾
        label = torch.LongTensor([item['label'][0][0]])
        
        return Data(x=features, edge_index=edge_index, edge_type=edge_type, 
                   sequence=sequence, y=label)


def load_data_lists():
    """åŠ è½½æ•°æ®åˆ—è¡¨"""
    logger.info("ğŸ“¥ åŠ è½½æ•°æ®åˆ—è¡¨...")
    
    with open('livable_multiclass_data/livable_train.json', 'r') as f:
        train_data = [item for item in json.load(f) if len(item['features']) > 0]
    with open('livable_multiclass_data/livable_valid.json', 'r') as f:
        valid_data = [item for item in json.load(f) if len(item['features']) > 0]
    with open('livable_multiclass_data/livable_test.json', 'r') as f:
        test_data = [item for item in json.load(f) if len(item['features']) > 0]
    
    logger.info(f"âœ… åŠ è½½å®Œæˆ: {len(train_data)} è®­ç»ƒ, {len(valid_data)} éªŒè¯, {len(test_data)} æµ‹è¯•æ ·æœ¬")
    return train_data, valid_data, test_data


def evaluate(model, data_loader, device, criterion):
    """è¯„ä¼°æ¨¡å‹"""
    model.eval()
    total_loss = 0
    all_predictions, all_targets = [], []
    
    with torch.no_grad():
        for data in data_loader:
            data = data.to(device)
            outputs = model(data)
            loss = criterion(outputs, data.y)
            total_loss += loss.item()
            
            _, predicted = torch.max(outputs.data, 1)
            all_predictions.extend(predicted.cpu().numpy())
            all_targets.extend(data.y.cpu().numpy())
    
    avg_loss = total_loss / len(data_loader)
    accuracy = accuracy_score(all_targets, all_predictions)
    _, _, f1, _ = precision_recall_fscore_support(all_targets, all_predictions, 
                                                 average='weighted', zero_division=0)
    
    return avg_loss, accuracy, f1, all_predictions, all_targets


def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    print("ğŸš€ å¼‚æ„å›¾ç¥ç»ç½‘ç»œè®­ç»ƒå¼€å§‹ (PyGç‰ˆæœ¬)")
    print("åŸºäºè¾¹ç±»å‹å¼‚æ„æ€§çš„LIVABLEæ”¹è¿›æ¨¡å‹")
    print("=" * 60)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    logger.info(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½æ•°æ®
    train_list, valid_list, test_list = load_data_lists()
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = HeterogeneousPygDataset(root='pyg_data/hetero_train', data_list=train_list)
    valid_dataset = HeterogeneousPygDataset(root='pyg_data/hetero_valid', data_list=valid_list)
    test_dataset = HeterogeneousPygDataset(root='pyg_data/hetero_test', data_list=test_list)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
    valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)
    
    logger.info(f"ğŸ“Š æ•°æ®åŠ è½½å™¨: è®­ç»ƒ{len(train_loader)}, éªŒè¯{len(valid_loader)}, æµ‹è¯•{len(test_loader)}æ‰¹æ¬¡")
    
    # åˆ›å»ºæ¨¡å‹
    model = HeterogeneousLIVABLEPygModel(
        input_dim=768,
        hidden_dim=256,
        seq_input_dim=128,
        num_classes=14,
        num_edge_types=4,
        num_gnn_layers=3,
        alpha=0.15,
        dropout=0.2
    ).to(device)
    
    param_count = sum(p.numel() for p in model.parameters())
    logger.info(f"ğŸ§  å¼‚æ„GNNæ¨¡å‹: {param_count:,} å‚æ•°")
    
    # è®¾ç½®ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)
    
    # è®­ç»ƒå‚æ•°
    num_epochs, patience, best_valid_f1, epochs_no_improve = 50, 10, 0, 0
    best_model_state = None
    
    logger.info(f"ğŸ¯ å¼€å§‹è®­ç»ƒï¼Œæœ€å¤š{num_epochs}è½®ï¼Œæ—©åœè€å¿ƒå€¼={patience}")
    
    # è®­ç»ƒå¾ªç¯
    for epoch in range(num_epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        total_train_loss = 0
        
        for data in tqdm(train_loader, desc=f"è®­ç»ƒ Epoch {epoch+1}/{num_epochs}"):
            data = data.to(device)
            optimizer.zero_grad()
            
            outputs = model(data)
            loss = criterion(outputs, data.y)
            total_train_loss += loss.item()
            
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()
        
        avg_train_loss = total_train_loss / len(train_loader)
        
        # éªŒè¯é˜¶æ®µ
        valid_loss, valid_acc, valid_f1, _, _ = evaluate(model, valid_loader, device, criterion)
        
        logger.info(f"Epoch {epoch+1} | è®­ç»ƒæŸå¤±: {avg_train_loss:.4f} | "
                   f"éªŒè¯æŸå¤±: {valid_loss:.4f}, å‡†ç¡®ç‡: {valid_acc:.4f}, F1: {valid_f1:.4f}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if valid_f1 > best_valid_f1:
            best_valid_f1 = valid_f1
            epochs_no_improve = 0
            best_model_state = copy.deepcopy(model.state_dict())
            logger.info(f"ğŸ† æ–°çš„æœ€ä½³éªŒè¯F1: {best_valid_f1:.4f}")
        else:
            epochs_no_improve += 1
        
        # æ—©åœæ£€æŸ¥
        if epochs_no_improve >= patience:
            logger.info(f"âš ï¸ æ—©åœè§¦å‘ï¼Œåœ¨ç¬¬{epoch+1}è½®åœæ­¢")
            break
    
    # åŠ è½½æœ€ä½³æ¨¡å‹
    if best_model_state:
        model.load_state_dict(best_model_state)
        logger.info("ğŸ’¾ å·²åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæœ€ç»ˆè¯„ä¼°")
    
    # æœ€ç»ˆæµ‹è¯•
    logger.info("ğŸ“Š åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æœ€ä½³æ¨¡å‹...")
    test_loss, test_acc, test_f1, test_preds, test_targets = evaluate(model, test_loader, device, criterion)
    
    print("\n" + "=" * 60)
    print("ğŸ‰ å¼‚æ„GNNè®­ç»ƒå®Œæˆ!")
    print(f"ğŸ† æœ€ä½³éªŒè¯F1: {best_valid_f1:.4f}")
    print(f"ğŸ¯ æœ€ç»ˆæµ‹è¯•ç»“æœ:")
    print(f"   å‡†ç¡®ç‡: {test_acc:.4f}")
    print(f"   F1åˆ†æ•°: {test_f1:.4f}")
    
    # è¾¹ç±»å‹é‡è¦æ€§åˆ†æ
    edge_importance = model.get_edge_type_importance()
    edge_names = ['AST', 'CFG', 'DFG', 'CDG']
    print(f"\nğŸ”— å­¦ä¹ åˆ°çš„è¾¹ç±»å‹é‡è¦æ€§:")
    for i, (name, importance) in enumerate(zip(edge_names, edge_importance)):
        print(f"   {name}: {importance.item():.4f}")
    
    # è¯¦ç»†åˆ†ç±»æŠ¥å‘Š
    with open('multiclass_label_mapping.json', 'r') as f:
        label_map = json.load(f)
    class_names = [label_map['label_to_cwe'][str(i)] for i in range(14)]
    
    print(f"\nğŸ“‹ æµ‹è¯•é›†åˆ†ç±»æŠ¥å‘Š:")
    report = classification_report(test_targets, test_preds, target_names=class_names, zero_division=0)
    print(report)
    
    # ä¿å­˜ç»“æœ
    results = {
        'best_valid_f1': best_valid_f1,
        'test_accuracy': test_acc,
        'test_f1': test_f1,
        'edge_type_importance': edge_importance.cpu().tolist(),
        'model_parameters': param_count
    }
    
    output_dir = Path("heterogeneous_gnn_pyg_results")
    output_dir.mkdir(exist_ok=True)
    
    with open(output_dir / "results.json", 'w') as f:
        json.dump(results, f, indent=2)
    
    torch.save(best_model_state, output_dir / "best_heterogeneous_model.pth")
    logger.info(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ° {output_dir}")
    
    print("=" * 60)


if __name__ == '__main__':
    main()