# 模型训练文件说明文档

本文档详细介绍了项目中各个训练脚本和模型文件的内容、作用及其区别。

## 一、核心训练脚本对比

### 1. `simplified_hetero_livable_fusion.py` - 异构GNN模型
**模型架构**：基于异构图神经网络的多类别漏洞检测模型  
**训练方式**：50轮训练集学习分析  
**损失函数**：标准交叉熵损失  

**核心特性**：
- **动态边权重学习**：模型自动学习AST、CFG、DFG、CDG四种边类型的重要性权重
- **异构消息传播**：为每种边类型使用专门的权重矩阵进行特征变换
- **图神经网络**：使用`HeterogeneousLIVABLEPygModel`，支持多层GNN传播
- **双分支架构**：图分支（节点特征） + 序列分支（时序特征）

**关键算法组件**：
```python
# 边类型重要性权重（可学习参数）
self.edge_type_importance = nn.Parameter(torch.ones(num_edge_types))

# 异构GNN层
self.hetero_gnn_layers = nn.ModuleList([
    HeterogeneousGNNLayer(...) for _ in range(num_gnn_layers)
])
```

**预期输出**：各边类型学习到的重要性权重，证明哪种代码关系对漏洞检测最关键

---

### 2. `train_hetero_gnn_sade_simple.py` - 异构GNN + SADE损失
**模型架构**：与上述相同的异构GNN架构  
**训练方式**：50轮训练集学习分析  
**损失函数**：**SADE自适应损失函数**  

**核心特性**：
- 继承异构GNN的所有优点（动态边权重学习）
- **SADE损失函数**：专门处理类别不平衡问题的自适应损失

**SADE损失函数详解**：
```python
class SADELoss(nn.Module):
    def __init__(self, num_classes, alpha=1.0, beta=2.0, gamma=0.5):
        # alpha: 基础权重
        # beta: 类别平衡权重  
        # gamma: 自适应权重
        
    def forward(self, predictions, targets):
        # 计算三种损失的组合：
        # 1. 标准交叉熵损失
        # 2. 类别权重调整损失（处理不平衡）
        # 3. 置信度自适应损失（关注困难样本）
        total_loss = alpha * ce_losses + beta * ce_losses * class_weights + sade_weights * ce_losses
```

**预期效果**：相比标准交叉熵，应该在尾部类别（如CWE-476、CWE-787等）上有更好的检测性能

---

### 3. `train_simple_livable_training_only.py` - 简化LIVABLE模型
**模型架构**：简化版LIVABLE架构  
**训练方式**：50轮训练集学习分析  
**损失函数**：标准交叉熵损失  

**核心特性**：
- **图分支**：简单MLP处理节点特征，没有复杂的图传播
- **序列分支**：双向GRU处理时序特征
- **特征融合**：图特征和序列特征concatenate后通过MLP分类

**模型结构**：
```python
class SimpleLIVABLEModel(nn.Module):
    def __init__(self):
        # 图分支：简单MLP
        self.graph_encoder = nn.Sequential(
            nn.Linear(768, 256), nn.ReLU(), nn.Dropout(0.2),
            nn.Linear(256, 256), nn.ReLU(), nn.Dropout(0.2)
        )
        
        # 序列分支：双向GRU
        self.seq_encoder = nn.GRU(..., bidirectional=True)
        
        # 融合和分类
        self.fusion = nn.Sequential(...)
        self.classifier = nn.Sequential(...)
```

**与完整LIVABLE的区别**：
- 没有APPNP图传播算法
- 图处理更简单，计算量更小
- 主要依赖序列特征进行分类

---

### 4. `train_full_livable_training_only.py` - 完整LIVABLE模型
**模型架构**：**原始完整版LIVABLE架构**  
**训练方式**：50轮训练集学习分析  
**损失函数**：标准交叉熵损失  

**核心特性**：
- **APPNP图传播**：原始LIVABLE的核心算法，K=16轮传播，α=0.1残差连接
- **双向GRU序列处理**：512隐藏层的强大序列编码能力
- **双池化策略**：平均池化 + 最大池化的组合
- **双分支相加融合**：graph_outputs + seq_outputs

**原始LIVABLE核心算法**：
```python
class FullLIVABLEPygModel(nn.Module):
    def __init__(self):
        # 原始LIVABLE的APPNP参数
        self.appnp = APPNP(K=16, alpha=0.1)  
        
        # 原始LIVABLE的GRU参数
        self.bigru_seq = nn.GRU(128, 512, bidirectional=True)
        
        # 原始LIVABLE的MLP读出层
        self.mlp_graph = MLPReadout(768, 14)
        self.mlp_seq = MLPReadout(1024, 14)  # 双向512*2
    
    def forward(self, data):
        # APPNP图传播（16轮迭代）
        x = self.appnp(x, edge_index)
        
        # 双向GRU + 双池化
        seq_out, _ = self.bigru_seq(sequence)
        seq1 = F.avg_pool1d(seq_out, seq_out.size(2)).squeeze(2)
        seq2 = F.max_pool1d(seq_out, seq_out.size(2)).squeeze(2)
        
        # 原始LIVABLE的相加融合
        return graph_outputs + seq_outputs
```

**理论优势**：
- APPNP算法能够捕获长距离的节点依赖关系
- 更强的图结构建模能力
- 在原始论文中证明有效的架构设计

---

## 二、关键模型组件文件

### `heterogeneous_gnn_pyg.py` - 异构GNN核心实现
这是异构图神经网络的核心实现文件，包含：

**主要类**：
1. **`HeterogeneousGNNLayer`**：异构消息传播层
   - 为每种边类型（AST、CFG、DFG、CDG）定义专用权重矩阵
   - 实现注意力机制和边类型嵌入
   - 支持残差连接和层归一化

2. **`HeterogeneousLIVABLEPygModel`**：完整异构模型
   - 多层异构GNN堆叠
   - 图分支 + 序列分支双路径
   - 可学习的边类型重要性权重

3. **`HeterogeneousPygDataset`**：PyTorch Geometric数据集适配器
   - 处理LIVABLE格式数据转换为PyG格式
   - 边类型映射：{'AST': 0, 'CFG': 1, 'DFG': 2, 'CDG': 3}

**创新点**：
- **动态边权重调整**：`self.edge_type_importance = nn.Parameter(torch.ones(4))`
- **异构注意力机制**：每种边类型有专门的注意力计算
- **领域知识初始化**：基于漏洞检测理论初始化边权重（DFG > AST > CFG > CDG）

---

## 三、训练结果分析

### 各模型的预期表现对比

| 模型 | 图处理能力 | 类别平衡处理 | 参数量 | 预期F1性能 | 主要优势 |
|------|------------|--------------|--------|-------------|-----------|
| 异构GNN | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | 高 | 0.18-0.20 | 动态边权重，精确图建模 |
| 异构GNN+SADE | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | 高 | 0.19-0.21 | 异构图+类别平衡 |
| 简化LIVABLE | ⭐⭐ | ⭐⭐⭐ | 中 | 0.15-0.17 | 轻量级，快速训练 |
| 完整LIVABLE | ⭐⭐⭐⭐ | ⭐⭐⭐ | 高 | 0.17-0.19 | 原始设计，APPNP传播 |

### 关键观察指标

1. **边类型重要性学习**（异构GNN模型）：
   ```
   预期结果：DFG > AST > CFG > CDG
   理论依据：数据流分析对漏洞检测最关键
   ```

2. **尾部类别改进**（SADE损失模型）：
   ```
   重点关注：CWE-476, CWE-787, CWE-284等低频类别
   期望：相对简单交叉熵有显著F1提升
   ```

3. **训练集学习曲线**：
   ```
   观察指标：
   - Loss下降趋势
   - 各类别准确率变化
   - 初始vs最终性能对比
   ```

---

## 四、实验设计意义

### 研究问题验证

1. **异构图神经网络 vs 传统LIVABLE**：
   - 验证动态边权重学习是否优于固定图结构处理
   - 对比异构建模和同构建模的效果差异

2. **SADE损失 vs 交叉熵损失**：
   - 验证自适应损失函数对严重类别不平衡的改善效果
   - 量化尾部类别检测性能提升

3. **简化 vs 完整架构**：
   - 验证模型复杂度与性能的权衡关系
   - 分析APPNP算法对图建模的实际贡献

### 实际应用价值

**对于软件安全领域**：
- 提供了多种漏洞检测模型的系统对比
- 验证了异构图建模在代码分析中的有效性
- 为处理不平衡安全数据集提供了解决方案

**对于机器学习研究**：
- 展示了图神经网络在结构化代码数据上的应用
- 提供了处理多类别不平衡问题的实用方法
- 验证了领域知识在模型设计中的重要性

---

## 五、文件依赖关系

```
项目根目录/
├── 核心训练脚本/
│   ├── simplified_hetero_livable_fusion.py     # 异构GNN
│   ├── train_hetero_gnn_sade_simple.py        # 异构GNN+SADE  
│   ├── train_simple_livable_training_only.py  # 简化LIVABLE
│   └── train_full_livable_training_only.py    # 完整LIVABLE
│
├── 核心模型实现/
│   ├── heterogeneous_gnn_pyg.py               # 异构GNN核心实现
│   ├── train_simple_livable.py                # 简化LIVABLE原始文件
│   └── train_full_livable_pyg.py              # 完整LIVABLE原始文件
│
├── 数据文件/
│   ├── livable_multiclass_data/
│   │   ├── livable_train.json                 # 训练数据
│   │   ├── livable_valid.json                 # 验证数据
│   │   └── livable_test.json                  # 测试数据
│   └── multiclass_label_mapping.json          # 类别映射
│
└── 结果输出目录/
    ├── livable_enhanced_hetero_training_analysis/
    ├── heterogeneous_gnn_sade_training_analysis/
    ├── simple_livable_training_analysis/
    └── full_livable_training_analysis/
```

## 总结

本项目通过四个不同的模型实现，系统地对比了：
1. 不同图神经网络架构的效果
2. 不同损失函数对类别不平衡的处理能力
3. 模型复杂度与性能的权衡关系

每个模型都经过50轮训练集学习，并输出详细的性能分析，为多类别软件漏洞检测提供了全面的技术方案对比。