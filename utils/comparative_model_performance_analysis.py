#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨¡å‹æ€§èƒ½å¯¹æ¯”åˆ†æè„šæœ¬
æ¯”è¾ƒä¸åŒæ¶æ„æ¨¡å‹åœ¨å¤šåˆ†ç±»æ¼æ´æ£€æµ‹ä»»åŠ¡ä¸Šçš„æ€§èƒ½
"""

import json
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from pathlib import Path
import seaborn as sns

def collect_model_results():
    """æ”¶é›†æ‰€æœ‰æ¨¡å‹çš„ç»“æœ"""
    results = {}
    
    # 1. å¼‚æ„GNN (PyGç‰ˆæœ¬)
    try:
        with open('heterogeneous_gnn_pyg_results/results.json', 'r') as f:
            hetero_results = json.load(f)
        results['Heterogeneous GNN'] = {
            'test_accuracy': hetero_results['test_accuracy'],
            'test_f1': hetero_results['test_f1'],
            'best_valid_f1': hetero_results['best_valid_f1'],
            'model_parameters': hetero_results['model_parameters'],
            'edge_importance': hetero_results['edge_type_importance'],
            'architecture': 'Heterogeneous Graph Neural Network',
            'key_features': ['Dynamic edge weights', 'Multi-edge types', 'Attention mechanism']
        }
    except FileNotFoundError:
        print("âš ï¸ å¼‚æ„GNNç»“æœæ–‡ä»¶æœªæ‰¾åˆ°ï¼Œå°†ä½¿ç”¨å½“å‰è®­ç»ƒç»“æœ")
        
    # 2. Simple LIVABLE
    try:
        with open('simple_livable_results/simple_livable_final_results.json', 'r') as f:
            simple_results = json.load(f)
        results['Simple LIVABLE'] = {
            'test_accuracy': simple_results['test_accuracy'],
            'test_f1': simple_results['test_f1'],
            'best_valid_f1': simple_results['best_valid_f1'],
            'model_parameters': simple_results['model_info']['total_params'],
            'architecture': 'Simplified LIVABLE (Graph + Sequence)',
            'key_features': ['Graph encoding', 'Sequence modeling', 'Feature fusion']
        }
    except FileNotFoundError:
        print("âš ï¸ Simple LIVABLEç»“æœæ–‡ä»¶æœªæ‰¾åˆ°")
        
    # 3. SADE Lossæ¨¡å‹
    try:
        with open('sade_training_results/sade_final_results.json', 'r') as f:
            sade_results = json.load(f)
        results['SADE Loss'] = {
            'test_accuracy': sade_results['test_accuracy'],
            'test_f1': sade_results['test_f1'],
            'best_valid_f1': sade_results['best_val_f1'],
            'model_parameters': sade_results['model_parameters'],
            'architecture': 'LIVABLE with Self-Adaptive Loss',
            'key_features': ['Adaptive loss weighting', 'Class imbalance handling', 'Dynamic adjustment']
        }
    except FileNotFoundError:
        print("âš ï¸ SADEç»“æœæ–‡ä»¶æœªæ‰¾åˆ°")
        
    # 4. æ ‡å‡†å¤šåˆ†ç±»æ¨¡å‹
    try:
        with open('multiclass_training_results/final_results.json', 'r') as f:
            multi_results = json.load(f)
        results['Standard Multiclass'] = {
            'test_accuracy': multi_results['test_accuracy'],
            'test_f1': multi_results['test_f1'],
            'best_valid_f1': multi_results['best_val_f1'],
            'model_parameters': multi_results['model_parameters'],
            'architecture': 'Standard LIVABLE Multiclass',
            'key_features': ['Basic graph features', 'Standard cross-entropy loss']
        }
    except FileNotFoundError:
        print("âš ï¸ æ ‡å‡†å¤šåˆ†ç±»ç»“æœæ–‡ä»¶æœªæ‰¾åˆ°")
    
    return results

def analyze_performance(results):
    """åˆ†ææ¨¡å‹æ€§èƒ½"""
    print("ğŸ” æ¨¡å‹æ€§èƒ½å¯¹æ¯”åˆ†æ")
    print("=" * 80)
    
    # åˆ›å»ºæ€§èƒ½å¯¹æ¯”DataFrame
    performance_data = []
    for model_name, metrics in results.items():
        performance_data.append({
            'Model': model_name,
            'Test Accuracy': metrics['test_accuracy'],
            'Test F1': metrics['test_f1'],
            'Best Valid F1': metrics['best_valid_f1'],
            'Parameters (M)': metrics['model_parameters'] / 1_000_000,
            'Architecture': metrics['architecture']
        })
    
    df = pd.DataFrame(performance_data)
    
    # æ’åºï¼šæŒ‰æµ‹è¯•F1åˆ†æ•°æ’åº
    df = df.sort_values('Test F1', ascending=False)
    
    print("\nğŸ“Š æ¨¡å‹æ€§èƒ½æ’å (æŒ‰æµ‹è¯•F1åˆ†æ•°æ’åº):")
    print("-" * 80)
    for idx, row in df.iterrows():
        print(f"{row.name + 1:2d}. {row['Model']:<20} | "
              f"Acc: {row['Test Accuracy']:.4f} | "
              f"F1: {row['Test F1']:.4f} | "
              f"Params: {row['Parameters (M)']:.2f}M")
    
    # æ€§èƒ½åˆ†æ
    print(f"\nğŸ† æœ€ä½³æ¨¡å‹åˆ†æ:")
    best_model = df.iloc[0]
    print(f"   æ¨¡å‹: {best_model['Model']}")
    print(f"   æ¶æ„: {best_model['Architecture']}")
    print(f"   æµ‹è¯•å‡†ç¡®ç‡: {best_model['Test Accuracy']:.4f}")
    print(f"   æµ‹è¯•F1åˆ†æ•°: {best_model['Test F1']:.4f}")
    print(f"   å‚æ•°é‡: {best_model['Parameters (M)']:.2f}M")
    
    # æ•ˆç‡åˆ†æ (F1/å‚æ•°æ¯”)
    df['Efficiency'] = df['Test F1'] / df['Parameters (M)']
    most_efficient = df.loc[df['Efficiency'].idxmax()]
    print(f"\nâš¡ æœ€é«˜æ•ˆæ¨¡å‹:")
    print(f"   æ¨¡å‹: {most_efficient['Model']}")
    print(f"   æ•ˆç‡æŒ‡æ ‡: {most_efficient['Efficiency']:.6f} (F1/Må‚æ•°)")
    
    return df, results

def create_comparison_plots(df, results):
    """åˆ›å»ºæ€§èƒ½å¯¹æ¯”å›¾è¡¨"""
    plt.style.use('seaborn-v0_8')
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # 1. å‡†ç¡®ç‡vs F1åˆ†æ•°æ•£ç‚¹å›¾
    ax1 = axes[0, 0]
    scatter = ax1.scatter(df['Test Accuracy'], df['Test F1'], 
                         s=df['Parameters (M)'] * 50, 
                         alpha=0.7, c=range(len(df)), cmap='viridis')
    
    for i, row in df.iterrows():
        ax1.annotate(row['Model'], 
                    (row['Test Accuracy'], row['Test F1']),
                    xytext=(5, 5), textcoords='offset points',
                    fontsize=9, alpha=0.8)
    
    ax1.set_xlabel('Test Accuracy')
    ax1.set_ylabel('Test F1 Score')
    ax1.set_title('Performance Comparison\n(Bubble size = Parameters)')
    ax1.grid(True, alpha=0.3)
    
    # 2. å‚æ•°é‡å¯¹æ¯”æ¡å½¢å›¾
    ax2 = axes[0, 1]
    bars = ax2.bar(range(len(df)), df['Parameters (M)'], 
                   color=plt.cm.viridis(np.linspace(0, 1, len(df))))
    ax2.set_xlabel('Models')
    ax2.set_ylabel('Parameters (Millions)')
    ax2.set_title('Model Complexity Comparison')
    ax2.set_xticks(range(len(df)))
    ax2.set_xticklabels([name[:10] + '...' if len(name) > 10 else name 
                        for name in df['Model']], rotation=45)
    
    # åœ¨æ¡å½¢ä¸Šæ·»åŠ æ•°å€¼
    for i, bar in enumerate(bars):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.2f}M', ha='center', va='bottom')
    
    # 3. F1åˆ†æ•°å¯¹æ¯”
    ax3 = axes[1, 0]
    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']
    bars = ax3.bar(df['Model'], df['Test F1'], 
                   color=colors[:len(df)])
    ax3.set_ylabel('Test F1 Score')
    ax3.set_title('F1 Score Comparison')
    ax3.set_xticklabels(df['Model'], rotation=45, ha='right')
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, bar in enumerate(bars):
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.4f}', ha='center', va='bottom')
    
    # 4. æ•ˆç‡åˆ†æ (F1/å‚æ•°æ¯”)
    ax4 = axes[1, 1]
    df_sorted_eff = df.sort_values('Efficiency', ascending=True)
    bars = ax4.barh(range(len(df_sorted_eff)), df_sorted_eff['Efficiency'],
                    color=plt.cm.plasma(np.linspace(0, 1, len(df_sorted_eff))))
    ax4.set_xlabel('Efficiency (F1 Score / Million Parameters)')
    ax4.set_title('Model Efficiency Comparison')
    ax4.set_yticks(range(len(df_sorted_eff)))
    ax4.set_yticklabels(df_sorted_eff['Model'])
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, bar in enumerate(bars):
        width = bar.get_width()
        ax4.text(width, bar.get_y() + bar.get_height()/2.,
                f'{width:.6f}', ha='left', va='center')
    
    plt.tight_layout()
    plt.savefig('model_performance_comparison.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    return fig

def analyze_edge_importance(results):
    """åˆ†æå¼‚æ„GNNçš„è¾¹ç±»å‹é‡è¦æ€§"""
    if 'Heterogeneous GNN' in results and 'edge_importance' in results['Heterogeneous GNN']:
        print(f"\nğŸ”— å¼‚æ„GNNè¾¹ç±»å‹é‡è¦æ€§åˆ†æ:")
        print("-" * 50)
        
        edge_names = ['AST', 'CFG', 'DFG', 'CDG']
        edge_weights = results['Heterogeneous GNN']['edge_importance']
        
        # åˆ›å»ºè¾¹ç±»å‹é‡è¦æ€§åˆ†æ
        for name, weight in zip(edge_names, edge_weights):
            bar = "â–ˆ" * int(weight * 50)  # å¯è§†åŒ–æƒé‡
            print(f"   {name:<4}: {weight:.4f} |{bar}")
        
        # æ‰¾å‡ºæœ€é‡è¦çš„è¾¹ç±»å‹
        most_important_idx = np.argmax(edge_weights)
        most_important_edge = edge_names[most_important_idx]
        print(f"\n   ğŸ¯ æœ€é‡è¦çš„è¾¹ç±»å‹: {most_important_edge} (æƒé‡: {edge_weights[most_important_idx]:.4f})")
        
        # è¾¹ç±»å‹é‡è¦æ€§çš„ç†è®ºåˆ†æ
        print(f"\n   ğŸ’¡ ç†è®ºåˆ†æ:")
        edge_analysis = {
            'AST': 'è¯­æ³•ç»“æ„æ ‘ - ä»£ç çš„è¯­æ³•å…³ç³»',
            'CFG': 'æ§åˆ¶æµå›¾ - ç¨‹åºæ‰§è¡Œè·¯å¾„',
            'DFG': 'æ•°æ®æµå›¾ - å˜é‡ä¾èµ–å…³ç³»',
            'CDG': 'æ§åˆ¶ä¾èµ–å›¾ - æ§åˆ¶è¯­å¥ä¾èµ–'
        }
        
        for name, weight in zip(edge_names, edge_weights):
            print(f"     {name}: {edge_analysis[name]} (å­¦ä¹ æƒé‡: {weight:.4f})")

def generate_detailed_report(df, results):
    """ç”Ÿæˆè¯¦ç»†çš„å¯¹æ¯”æŠ¥å‘Š"""
    report = []
    report.append("# ğŸ¯ å¤šåˆ†ç±»æ¼æ´æ£€æµ‹æ¨¡å‹æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š")
    report.append("=" * 60)
    report.append("")
    
    # æ¦‚è¿°
    report.append("## ğŸ“Š å®éªŒæ¦‚è¿°")
    report.append("")
    report.append("æœ¬æŠ¥å‘Šå¯¹æ¯”äº†å››ç§ä¸åŒæ¶æ„çš„æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨14ç±»CWEæ¼æ´æ£€æµ‹ä»»åŠ¡ä¸Šçš„æ€§èƒ½è¡¨ç°:")
    report.append("")
    
    for i, (model_name, model_data) in enumerate(results.items(), 1):
        report.append(f"{i}. **{model_name}**: {model_data['architecture']}")
        key_features = ', '.join(model_data['key_features'])
        report.append(f"   - æ ¸å¿ƒç‰¹æ€§: {key_features}")
        report.append("")
    
    # æ€§èƒ½æ’å
    report.append("## ğŸ† æ€§èƒ½æ’å")
    report.append("")
    report.append("| æ’å | æ¨¡å‹åç§° | æµ‹è¯•å‡†ç¡®ç‡ | æµ‹è¯•F1 | éªŒè¯F1 | å‚æ•°é‡(M) |")
    report.append("|------|----------|-----------|--------|--------|----------|")
    
    for idx, row in df.iterrows():
        report.append(f"| {idx+1} | {row['Model']} | {row['Test Accuracy']:.4f} | "
                     f"{row['Test F1']:.4f} | {row['Best Valid F1']:.4f} | {row['Parameters (M)']:.2f} |")
    
    report.append("")
    
    # è¯¦ç»†åˆ†æ
    report.append("## ğŸ” è¯¦ç»†æ€§èƒ½åˆ†æ")
    report.append("")
    
    best_model = df.iloc[0]
    worst_model = df.iloc[-1]
    
    report.append(f"### ğŸ¥‡ æœ€ä½³æ€§èƒ½æ¨¡å‹: {best_model['Model']}")
    report.append("")
    report.append(f"- **æµ‹è¯•å‡†ç¡®ç‡**: {best_model['Test Accuracy']:.4f}")
    report.append(f"- **æµ‹è¯•F1åˆ†æ•°**: {best_model['Test F1']:.4f}")
    report.append(f"- **å‚æ•°é‡**: {best_model['Parameters (M)']:.2f}M")
    report.append("")
    
    if 'Heterogeneous GNN' in results:
        hetero_data = results['Heterogeneous GNN']
        if 'edge_importance' in hetero_data:
            report.append("#### ğŸ”— è¾¹ç±»å‹é‡è¦æ€§åˆ†æ (ä»…å¼‚æ„GNN)")
            edge_names = ['AST', 'CFG', 'DFG', 'CDG']
            edge_weights = hetero_data['edge_importance']
            
            for name, weight in zip(edge_names, edge_weights):
                report.append(f"- **{name}**: {weight:.4f}")
            report.append("")
    
    # æ•ˆç‡åˆ†æ
    df_eff = df.copy()
    df_eff['Efficiency'] = df_eff['Test F1'] / df_eff['Parameters (M)']
    most_efficient = df_eff.loc[df_eff['Efficiency'].idxmax()]
    
    report.append(f"### âš¡ æœ€é«˜æ•ˆæ¨¡å‹: {most_efficient['Model']}")
    report.append("")
    report.append(f"- **æ•ˆç‡æŒ‡æ ‡**: {most_efficient['Efficiency']:.6f} (F1åˆ†æ•°/ç™¾ä¸‡å‚æ•°)")
    report.append(f"- **æµ‹è¯•F1**: {most_efficient['Test F1']:.4f}")
    report.append(f"- **å‚æ•°é‡**: {most_efficient['Parameters (M)']:.2f}M")
    report.append("")
    
    # å…³é”®å‘ç°
    report.append("## ğŸ¯ å…³é”®å‘ç°")
    report.append("")
    
    performance_gap = best_model['Test F1'] - worst_model['Test F1']
    report.append(f"1. **æ€§èƒ½å·®è·**: æœ€ä½³ä¸æœ€å·®æ¨¡å‹F1åˆ†æ•°å·®è·ä¸º {performance_gap:.4f}")
    
    avg_accuracy = df['Test Accuracy'].mean()
    avg_f1 = df['Test F1'].mean()
    report.append(f"2. **å¹³å‡æ€§èƒ½**: å¹³å‡å‡†ç¡®ç‡ {avg_accuracy:.4f}, å¹³å‡F1åˆ†æ•° {avg_f1:.4f}")
    
    max_params = df['Parameters (M)'].max()
    min_params = df['Parameters (M)'].min()
    report.append(f"3. **æ¨¡å‹å¤æ‚åº¦**: å‚æ•°é‡èŒƒå›´ä» {min_params:.2f}M åˆ° {max_params:.2f}M")
    
    report.append("")
    report.append("## ğŸ’¡ ç»“è®ºä¸å»ºè®®")
    report.append("")
    
    if best_model['Model'] == 'Heterogeneous GNN':
        report.append("å¼‚æ„å›¾ç¥ç»ç½‘ç»œåœ¨å¤šåˆ†ç±»æ¼æ´æ£€æµ‹ä»»åŠ¡ä¸Šè¡¨ç°æœ€ä½³ï¼Œå…¶åŠ¨æ€è¾¹æƒé‡è°ƒæ•´æœºåˆ¶")
        report.append("å’Œå¤šç±»å‹è¾¹å»ºæ¨¡èƒ½åŠ›ä¸ºå…¶å¸¦æ¥äº†æ˜¾è‘—çš„æ€§èƒ½ä¼˜åŠ¿ã€‚")
    else:
        report.append(f"{best_model['Model']} åœ¨æ­¤ä»»åŠ¡ä¸Šè¡¨ç°æœ€ä½³ï¼Œå±•ç°äº†å…¶æ¶æ„è®¾è®¡çš„æœ‰æ•ˆæ€§ã€‚")
    
    report.append("")
    report.append("**å»ºè®®**:")
    report.append("- å¯¹äºè¿½æ±‚æœ€é«˜æ€§èƒ½çš„åœºæ™¯ï¼Œæ¨èä½¿ç”¨æ€§èƒ½æœ€ä½³çš„æ¨¡å‹")
    report.append("- å¯¹äºèµ„æºå—é™çš„ç¯å¢ƒï¼Œæ¨èä½¿ç”¨æ•ˆç‡æœ€é«˜çš„æ¨¡å‹")
    report.append("- å¯ä»¥è€ƒè™‘æ¨¡å‹é›†æˆæ¥è¿›ä¸€æ­¥æå‡æ€§èƒ½")
    
    return "\n".join(report)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ¨¡å‹æ€§èƒ½å¯¹æ¯”åˆ†æ...")
    
    # æ”¶é›†ç»“æœ
    results = collect_model_results()
    
    if not results:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æ¨¡å‹ç»“æœæ–‡ä»¶")
        return
    
    print(f"âœ… æˆåŠŸåŠ è½½ {len(results)} ä¸ªæ¨¡å‹çš„ç»“æœ")
    
    # æ€§èƒ½åˆ†æ
    df, results = analyze_performance(results)
    
    # è¾¹ç±»å‹é‡è¦æ€§åˆ†æ
    analyze_edge_importance(results)
    
    # åˆ›å»ºå¯¹æ¯”å›¾è¡¨
    print(f"\nğŸ“Š ç”Ÿæˆæ€§èƒ½å¯¹æ¯”å›¾è¡¨...")
    create_comparison_plots(df, results)
    
    # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
    print(f"\nğŸ“ ç”Ÿæˆè¯¦ç»†å¯¹æ¯”æŠ¥å‘Š...")
    detailed_report = generate_detailed_report(df, results)
    
    # ä¿å­˜æŠ¥å‘Š
    with open('comprehensive_model_comparison_report.md', 'w', encoding='utf-8') as f:
        f.write(detailed_report)
    
    # ä¿å­˜æ•°æ®
    df.to_csv('model_performance_comparison.csv', index=False)
    
    print(f"\nğŸ‰ åˆ†æå®Œæˆ!")
    print(f"ğŸ“ æ–‡ä»¶å·²ä¿å­˜:")
    print(f"   - comprehensive_model_comparison_report.md (è¯¦ç»†æŠ¥å‘Š)")
    print(f"   - model_performance_comparison.csv (æ€§èƒ½æ•°æ®)")
    print(f"   - model_performance_comparison.png (å¯¹æ¯”å›¾è¡¨)")

if __name__ == "__main__":
    main()