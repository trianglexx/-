#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¼‚æ„GNN + LIVABLEèåˆæ¶æ„
ç»“åˆå¼‚æ„GNNçš„è¾¹ç±»å‹å»ºæ¨¡èƒ½åŠ›ä¸åŸå§‹LIVABLEçš„APPNPç®—æ³•
"""

import json
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import numpy as np
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix
import logging
from pathlib import Path
from tqdm import tqdm
import copy
from typing import Dict, List, Optional

# PyG Imports
try:
    from torch_geometric.data import Dataset, Data
    from torch_geometric.loader import DataLoader
    from torch_geometric.nn import MessagePassing, global_mean_pool, global_max_pool
    from torch_geometric.utils import add_self_loops, degree
except ImportError:
    print("âŒ PyTorch Geometricä¸å¯ç”¨ï¼Œè¯·å®‰è£… pip install torch-geometric")
    exit(1)

logging.basicConfig(level=logging.INFO, format='[%(asctime)s] INFO: %(message)s', datefmt='%H:%M:%S')
logger = logging.getLogger(__name__)


class APPNPLayer(nn.Module):
    """
    APPNPå±‚çš„PyTorch Geometricå®ç°
    åŸºäºåŸå§‹LIVABLEçš„APPNPç®—æ³•ï¼Œä½†é€‚é…å¼‚æ„å›¾ç»“æ„
    """
    def __init__(self, k: int = 16, alpha: float = 0.1, dropout: float = 0.5):
        super(APPNPLayer, self).__init__()
        self.k = k
        self.alpha = alpha
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, x: torch.Tensor, edge_index: torch.Tensor, 
                edge_type: Optional[torch.Tensor] = None,
                initial_x: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        APPNPå‰å‘ä¼ æ’­
        H^{l+1} = (1-Î±) * æ¶ˆæ¯ä¼ é€’ + Î± * H^{0}
        """
        if initial_x is None:
            initial_x = x
            
        h = x
        
        # kæ¬¡APPNPè¿­ä»£
        for _ in range(self.k):
            # åº”ç”¨dropoutåˆ°è¾¹
            if self.training:
                # éšæœºä¸¢å¼ƒè¾¹
                mask = torch.rand(edge_index.size(1), device=edge_index.device) > self.dropout.p
                masked_edge_index = edge_index[:, mask]
                if edge_type is not None:
                    masked_edge_type = edge_type[mask]
                else:
                    masked_edge_type = None
            else:
                masked_edge_index = edge_index
                masked_edge_type = edge_type
            
            # è®¡ç®—åº¦å½’ä¸€åŒ–çš„é‚»æ¥çŸ©é˜µæ¶ˆæ¯ä¼ é€’
            if masked_edge_index.size(1) > 0:
                # æ·»åŠ è‡ªç¯
                masked_edge_index, _ = add_self_loops(masked_edge_index, num_nodes=x.size(0))
                
                # è®¡ç®—åº¦
                row, col = masked_edge_index
                deg = degree(col, x.size(0), dtype=x.dtype)
                deg_inv_sqrt = deg.pow(-0.5)
                deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0
                
                # å½’ä¸€åŒ–æ¶ˆæ¯ä¼ é€’
                norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]
                
                # èšåˆé‚»å±…ç‰¹å¾
                h_neighbors = torch.zeros_like(h)
                h_neighbors.index_add_(0, col, norm.view(-1, 1) * h[row])
                
                # APPNPæ›´æ–°ï¼š(1-Î±) * é‚»å±…èšåˆ + Î± * åˆå§‹ç‰¹å¾
                h = (1 - self.alpha) * h_neighbors + self.alpha * initial_x
            else:
                # å¦‚æœæ²¡æœ‰è¾¹ï¼Œåªä¿ç•™åˆå§‹ç‰¹å¾
                h = initial_x
                
        return h


class HeteroAPPNPLayer(MessagePassing):
    """
    å¼‚æ„APPNPå±‚ï¼šç»“åˆè¾¹ç±»å‹ç‰¹å®šçš„APPNPä¼ æ’­
    """
    def __init__(self, input_dim: int, output_dim: int, num_edge_types: int = 4,
                 k: int = 16, alpha: float = 0.1, dropout: float = 0.5):
        super(HeteroAPPNPLayer, self).__init__(aggr='add')
        
        self.input_dim = input_dim
        self.output_dim = output_dim
        self.num_edge_types = num_edge_types
        self.k = k
        self.alpha = alpha
        
        # ä¸ºæ¯ç§è¾¹ç±»å‹å®šä¹‰ä¸“ç”¨æƒé‡çŸ©é˜µ
        self.edge_type_weights = nn.ModuleList([
            nn.Linear(input_dim, output_dim, bias=False)
            for _ in range(num_edge_types)
        ])
        
        # è¾“å…¥æŠ•å½±
        if input_dim != output_dim:
            self.input_projection = nn.Linear(input_dim, output_dim, bias=False)
        else:
            self.input_projection = nn.Identity()
            
        # è¾¹ç±»å‹é‡è¦æ€§æƒé‡ï¼ˆå¯å­¦ä¹ ï¼‰
        self.edge_importance = nn.Parameter(torch.ones(num_edge_types))
        
        # APPNPå±‚
        self.appnp = APPNPLayer(k=k, alpha=alpha, dropout=dropout)
        
        # æ­£åˆ™åŒ–
        self.dropout = nn.Dropout(dropout)
        self.layer_norm = nn.LayerNorm(output_dim)
        
        self.reset_parameters()
        
    def reset_parameters(self):
        """å‚æ•°åˆå§‹åŒ–"""
        gain = nn.init.calculate_gain('relu')
        for i in range(self.num_edge_types):
            nn.init.xavier_uniform_(self.edge_type_weights[i].weight, gain=gain)
            
        if hasattr(self.input_projection, 'weight'):
            nn.init.xavier_uniform_(self.input_projection.weight, gain=gain)
            
        # åˆå§‹åŒ–è¾¹ç±»å‹é‡è¦æ€§
        with torch.no_grad():
            # åŸºäºæ¼æ´æ£€æµ‹å…ˆéªŒ: DFG > AST > CFG > CDG
            prior_weights = torch.tensor([1.2, 1.1, 1.4, 0.9])  # AST, CFG, DFG, CDG
            self.edge_importance.data = prior_weights
    
    def forward(self, x: torch.Tensor, edge_index_dict: Dict[str, torch.Tensor]) -> torch.Tensor:
        """å‰å‘ä¼ æ’­"""
        # è¾“å…¥æŠ•å½±
        h_initial = self.input_projection(x)
        
        # ä¸ºæ¯ç§è¾¹ç±»å‹åˆ†åˆ«åº”ç”¨å˜æ¢å’ŒAPPNP
        edge_outputs = []
        edge_names = ['AST', 'CFG', 'DFG', 'CDG']
        edge_weights = F.softmax(self.edge_importance, dim=0)
        
        for i, edge_name in enumerate(edge_names):
            if edge_name in edge_index_dict and edge_index_dict[edge_name].size(1) > 0:
                # åº”ç”¨è¾¹ç±»å‹ç‰¹å®šå˜æ¢
                h_transformed = self.edge_type_weights[i](x)
                
                # APPNPä¼ æ’­
                h_propagated = self.appnp(h_transformed, edge_index_dict[edge_name], initial_x=h_initial)
                
                # åº”ç”¨è¾¹ç±»å‹æƒé‡
                h_weighted = h_propagated * edge_weights[i]
                edge_outputs.append(h_weighted)
            else:
                # å¦‚æœæ²¡æœ‰è¯¥ç±»å‹çš„è¾¹ï¼Œä½¿ç”¨åˆå§‹ç‰¹å¾
                edge_outputs.append(h_initial * edge_weights[i])
        
        # èšåˆæ‰€æœ‰è¾¹ç±»å‹çš„è¾“å‡º
        if edge_outputs:
            h_final = torch.stack(edge_outputs, dim=0).sum(dim=0)
        else:
            h_final = h_initial
            
        # æ­£åˆ™åŒ–å’Œæ¿€æ´»
        h_final = self.dropout(h_final)
        h_final = self.layer_norm(h_final)
        h_final = F.gelu(h_final)
        
        return h_final


class LIVABLESequenceEncoder(nn.Module):
    """
    åŸå§‹LIVABLEçš„åºåˆ—ç¼–ç å™¨
    åŒå‘GRU + åŒæ± åŒ–ç­–ç•¥
    """
    def __init__(self, input_dim: int = 768, hidden_dim: int = 256, num_layers: int = 2):
        super(LIVABLESequenceEncoder, self).__init__()
        
        self.hidden_dim = hidden_dim
        
        # åŒå‘GRUï¼ˆä»¿ç…§åŸå§‹LIVABLEï¼‰
        self.bigru = nn.GRU(
            input_size=input_dim,
            hidden_size=hidden_dim,
            num_layers=num_layers,
            bidirectional=True,
            batch_first=True,
            dropout=0.2 if num_layers > 1 else 0
        )
        
        # è¾“å‡ºç»´åº¦æ˜¯åŒå‘çš„ï¼Œæ‰€ä»¥æ˜¯ hidden_dim * 2
        
    def forward(self, sequences: torch.Tensor) -> torch.Tensor:
        """
        åºåˆ—ç¼–ç 
        Args:
            sequences: [batch_size, seq_len, input_dim]
        Returns:
            pooled_features: [batch_size, hidden_dim * 2]
        """
        # åŒå‘GRUå¤„ç†
        gru_output, _ = self.bigru(sequences)  # [batch_size, seq_len, hidden_dim * 2]
        
        # æ£€æŸ¥ç»´åº¦å¹¶è¿›è¡Œè½¬ç½®
        if gru_output.dim() == 3 and gru_output.size(1) > 1:
            # è½¬ç½®ä»¥ä¾¿æ± åŒ–: [batch_size, hidden_dim * 2, seq_len]
            gru_output = gru_output.transpose(1, 2)
            
            # åŒæ± åŒ–ç­–ç•¥ï¼ˆä»¿ç…§åŸå§‹LIVABLEï¼‰
            avg_pooled = F.avg_pool1d(gru_output, gru_output.size(2)).squeeze(2)  # [batch_size, hidden_dim * 2]
            max_pooled = F.max_pool1d(gru_output, gru_output.size(2)).squeeze(2)  # [batch_size, hidden_dim * 2]
        else:
            # å¦‚æœåºåˆ—é•¿åº¦ä¸º1æˆ–ç»´åº¦ä¸åŒ¹é…ï¼Œç›´æ¥ä½¿ç”¨meanå’Œmax
            avg_pooled = gru_output.mean(dim=1)  # [batch_size, hidden_dim * 2]
            max_pooled = gru_output.max(dim=1)[0]  # [batch_size, hidden_dim * 2]
        
        # ç›¸åŠ èåˆï¼ˆåŸå§‹LIVABLEçš„ç­–ç•¥ï¼‰
        pooled_features = avg_pooled + max_pooled
        
        # ç¡®ä¿è¾“å‡ºç»´åº¦æ­£ç¡®
        if pooled_features.dim() == 1:
            pooled_features = pooled_features.unsqueeze(0)
        
        return pooled_features


class HeteroGNNLIVABLEFusion(nn.Module):
    """
    å¼‚æ„GNN + LIVABLEèåˆæ¨¡å‹
    ç»“åˆå¼‚æ„å›¾ç¥ç»ç½‘ç»œå’ŒLIVABLEçš„ä¼˜ç§€ç®—æ³•
    """
    def __init__(self, 
                 input_dim: int = 768,
                 hidden_dim: int = 256,
                 num_classes: int = 14,
                 num_layers: int = 3,
                 num_edge_types: int = 4,
                 appnp_k: int = 16,
                 appnp_alpha: float = 0.1,
                 dropout: float = 0.2):
        super(HeteroGNNLIVABLEFusion, self).__init__()
        
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.num_classes = num_classes
        
        # è¾“å…¥æŠ•å½±
        self.input_projection = nn.Linear(input_dim, hidden_dim)
        
        # å¼‚æ„APPNPå±‚ï¼ˆå¤šå±‚å †å ï¼‰
        self.hetero_appnp_layers = nn.ModuleList([
            HeteroAPPNPLayer(
                input_dim=hidden_dim,
                output_dim=hidden_dim,
                num_edge_types=num_edge_types,
                k=appnp_k,
                alpha=appnp_alpha,
                dropout=dropout
            ) for _ in range(num_layers)
        ])
        
        # LIVABLEåºåˆ—ç¼–ç å™¨
        self.sequence_encoder = LIVABLESequenceEncoder(
            input_dim=input_dim,
            hidden_dim=hidden_dim // 2,  # å› ä¸ºåŒå‘GRUè¾“å‡ºæ˜¯hidden_dim * 2
            num_layers=2
        )
        
        # å›¾åˆ†æ”¯MLPï¼ˆä»¿ç…§åŸå§‹LIVABLEï¼‰
        self.graph_mlp = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim // 2, num_classes)
        )
        
        # åºåˆ—åˆ†æ”¯MLPï¼ˆä»¿ç…§åŸå§‹LIVABLEï¼‰
        # åºåˆ—ç¼–ç å™¨è¾“å‡ºç»´åº¦æ˜¯ hidden_dim (å› ä¸ºåŒå‘GRU: (hidden_dim//2) * 2 = hidden_dim)
        self.sequence_mlp = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(), 
            nn.Dropout(dropout),
            nn.Linear(hidden_dim // 2, num_classes)
        )
        
        # å…¨å±€dropout
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, data):
        """å‰å‘ä¼ æ’­"""
        x, edge_index_dict, batch = data.x, data.edge_index_dict, data.batch
        sequence_features = data.sequence_features
        
        # === å›¾åˆ†æ”¯ï¼šå¼‚æ„APPNPå¤„ç† ===
        # è¾“å…¥æŠ•å½±
        h = self.input_projection(x)
        h = F.relu(h)
        h = self.dropout(h)
        
        # å¤šå±‚å¼‚æ„APPNP
        for appnp_layer in self.hetero_appnp_layers:
            h_new = appnp_layer(h, edge_index_dict)
            h = h_new + h  # æ®‹å·®è¿æ¥
        
        # å›¾çº§åˆ«æ± åŒ–ï¼ˆåŒæ± åŒ–ç­–ç•¥ï¼‰
        graph_avg = global_mean_pool(h, batch)
        graph_max = global_max_pool(h, batch)
        graph_features = graph_avg + graph_max  # ä»¿ç…§LIVABLEçš„ç›¸åŠ ç­–ç•¥
        
        # å›¾åˆ†æ”¯åˆ†ç±»
        graph_outputs = self.graph_mlp(self.dropout(graph_features))
        
        # === åºåˆ—åˆ†æ”¯ï¼šLIVABLEåºåˆ—ç¼–ç  ===
        batch_size = int(batch.max().item() + 1)
        
        # é‡æ–°ç»„ç»‡åºåˆ—ç‰¹å¾
        sequence_input_list = []
        for i in range(batch_size):
            mask = (batch == i)
            sample_idx = mask.nonzero(as_tuple=True)[0][0]
            seq_feat = sequence_features[sample_idx]
            sequence_input_list.append(seq_feat)
        
        # å¡«å……åˆ°ç›¸åŒé•¿åº¦
        max_seq_len = max(seq.size(0) for seq in sequence_input_list)
        padded_sequences = []
        
        for seq in sequence_input_list:
            if seq.size(0) < max_seq_len:
                padding = torch.zeros(max_seq_len - seq.size(0), seq.size(1)).to(seq.device)
                seq = torch.cat([seq, padding], dim=0)
            padded_sequences.append(seq)
        
        sequence_input = torch.stack(padded_sequences, dim=0)
        
        # LIVABLEåºåˆ—ç¼–ç 
        sequence_features_encoded = self.sequence_encoder(sequence_input)
        
        # è°ƒè¯•ä¿¡æ¯
        print(f"Debug: sequence_input shape: {sequence_input.shape}")
        print(f"Debug: sequence_features_encoded shape: {sequence_features_encoded.shape}")
        
        # ç¡®ä¿ç»´åº¦æ­£ç¡®
        if sequence_features_encoded.dim() == 1:
            sequence_features_encoded = sequence_features_encoded.unsqueeze(0)
        elif sequence_features_encoded.size(0) == 1 and batch_size > 1:
            # å¦‚æœbatchå¤„ç†å‡ºç°é—®é¢˜ï¼Œé‡å¤ç‰¹å¾ä»¥åŒ¹é…batch_size
            sequence_features_encoded = sequence_features_encoded.repeat(batch_size, 1)
        
        # åºåˆ—åˆ†æ”¯åˆ†ç±»
        sequence_outputs = self.sequence_mlp(self.dropout(sequence_features_encoded))
        
        # === ç‰¹å¾èåˆï¼ˆåŸå§‹LIVABLEç­–ç•¥ï¼‰===
        # ç›´æ¥ç›¸åŠ ï¼Œä¿æŒä¸¤ä¸ªåˆ†æ”¯çš„å¹³ç­‰è´¡çŒ®
        final_outputs = graph_outputs + sequence_outputs
        
        return final_outputs
    
    def get_edge_importance_weights(self):
        """è·å–å­¦ä¹ åˆ°çš„è¾¹ç±»å‹é‡è¦æ€§æƒé‡"""
        weights_per_layer = []
        for layer in self.hetero_appnp_layers:
            layer_weights = F.softmax(layer.edge_importance, dim=0).cpu().detach().numpy()
            weights_per_layer.append(layer_weights)
        
        # è¿”å›æ‰€æœ‰å±‚çš„å¹³å‡æƒé‡
        avg_weights = np.mean(weights_per_layer, axis=0)
        return avg_weights.tolist()


class HeteroLIVABLEDataset(Dataset):
    """å¼‚æ„LIVABLEæ•°æ®é›†"""
    def __init__(self, data_list, max_seq_len=6):
        self.data_list = data_list
        self.max_seq_len = max_seq_len
        self.edge_type_mapping = {'AST': 0, 'CFG': 1, 'DFG': 2, 'CDG': 3}
        super(HeteroLIVABLEDataset, self).__init__()
    
    def len(self):
        return len(self.data_list)
    
    def get(self, idx):
        sample = self.data_list[idx]
        
        # èŠ‚ç‚¹ç‰¹å¾å’Œåºåˆ—ç‰¹å¾
        features_seq = torch.tensor(sample['features'], dtype=torch.float32)
        node_features = features_seq[-1:, :]  # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥ä½œä¸ºèŠ‚ç‚¹ç‰¹å¾
        num_nodes = node_features.shape[0]
        
        # è¾¹ç´¢å¼•å­—å…¸
        edge_index_dict = {}
        for edge_type_name in self.edge_type_mapping.keys():
            edge_index_dict[edge_type_name] = torch.tensor([], dtype=torch.long).view(2, 0)
        
        # å¤„ç†å›¾ç»“æ„
        if 'structure' in sample:
            for edge_info in sample['structure']:
                source, edge_type, target = edge_info
                if source < num_nodes and target < num_nodes and edge_type in self.edge_type_mapping:
                    if edge_index_dict[edge_type].size(1) == 0:
                        edge_index_dict[edge_type] = torch.tensor([[source], [target]], dtype=torch.long)
                    else:
                        new_edge = torch.tensor([[source], [target]], dtype=torch.long)
                        edge_index_dict[edge_type] = torch.cat([edge_index_dict[edge_type], new_edge], dim=1)
        
        # æ ‡ç­¾
        label = torch.tensor(sample['label'], dtype=torch.long)
        
        # åˆ›å»ºDataå¯¹è±¡
        data = Data(
            x=node_features,
            edge_index_dict=edge_index_dict,
            sequence_features=features_seq,
            y=label
        )
        
        return data


def train_hetero_livable_fusion():
    """è®­ç»ƒå¼‚æ„GNN + LIVABLEèåˆæ¨¡å‹"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    logger.info(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½æ•°æ®
    logger.info("ğŸ“‚ åŠ è½½æ•°æ®...")
    with open('livable_multiclass_data/livable_train.json', 'r') as f:
        train_data = json.load(f)
    with open('livable_multiclass_data/livable_valid.json', 'r') as f:
        valid_data = json.load(f)
    with open('livable_multiclass_data/livable_test.json', 'r') as f:
        test_data = json.load(f)
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = HeteroLIVABLEDataset(train_data, max_seq_len=6)
    valid_dataset = HeteroLIVABLEDataset(valid_data, max_seq_len=6)
    test_dataset = HeteroLIVABLEDataset(test_data, max_seq_len=6)
    
    # æ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
    valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
    
    # åˆ›å»ºæ¨¡å‹
    model = HeteroGNNLIVABLEFusion(
        input_dim=768,
        hidden_dim=256,
        num_classes=14,
        num_layers=3,
        appnp_k=16,  # åŸå§‹LIVABLEçš„kå€¼
        appnp_alpha=0.1,  # åŸå§‹LIVABLEçš„Î±å€¼
        dropout=0.2
    ).to(device)
    
    # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.7, patience=5)
    
    # è®­ç»ƒå‚æ•°
    num_epochs = 30
    best_valid_f1 = 0.0
    best_model = None
    patience = 10
    patience_counter = 0
    
    logger.info("ğŸš€ å¼€å§‹è®­ç»ƒå¼‚æ„GNN + LIVABLEèåˆæ¨¡å‹")
    
    training_history = {
        'train_loss': [],
        'train_f1': [],
        'valid_f1': []
    }
    
    for epoch in range(num_epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        total_loss = 0.0
        all_preds = []
        all_labels = []
        
        for batch in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs}"):
            batch = batch.to(device)
            
            optimizer.zero_grad()
            
            outputs = model(batch)
            loss = criterion(outputs, batch.y)
            
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            
            preds = torch.argmax(outputs, dim=1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(batch.y.cpu().numpy())
        
        # è®¡ç®—è®­ç»ƒæŒ‡æ ‡
        train_loss = total_loss / len(train_loader)
        _, _, train_f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        valid_preds = []
        valid_labels = []
        
        with torch.no_grad():
            for batch in valid_loader:
                batch = batch.to(device)
                outputs = model(batch)
                preds = torch.argmax(outputs, dim=1)
                valid_preds.extend(preds.cpu().numpy())
                valid_labels.extend(batch.y.cpu().numpy())
        
        _, _, valid_f1, _ = precision_recall_fscore_support(valid_labels, valid_preds, average='weighted')
        
        # è®°å½•å†å²
        training_history['train_loss'].append(train_loss)
        training_history['train_f1'].append(train_f1)
        training_history['valid_f1'].append(valid_f1)
        
        logger.info(f"Epoch {epoch+1}: Loss={train_loss:.4f}, Train F1={train_f1:.4f}, Valid F1={valid_f1:.4f}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if valid_f1 > best_valid_f1:
            best_valid_f1 = valid_f1
            best_model = copy.deepcopy(model)
            patience_counter = 0
            logger.info(f"ğŸ¯ æ–°çš„æœ€ä½³éªŒè¯F1: {best_valid_f1:.4f}")
        else:
            patience_counter += 1
        
        # å­¦ä¹ ç‡è°ƒæ•´
        scheduler.step(valid_f1)
        
        # æ—©åœ
        if patience_counter >= patience:
            logger.info(f"â° æ—©åœè§¦å‘ï¼Œæœ€ä½³éªŒè¯F1: {best_valid_f1:.4f}")
            break
    
    # æµ‹è¯•é˜¶æ®µ
    logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•...")
    best_model.eval()
    test_preds = []
    test_labels = []
    
    with torch.no_grad():
        for batch in test_loader:
            batch = batch.to(device)
            outputs = best_model(batch)
            preds = torch.argmax(outputs, dim=1)
            test_preds.extend(preds.cpu().numpy())
            test_labels.extend(batch.y.cpu().numpy())
    
    # è®¡ç®—æµ‹è¯•æŒ‡æ ‡
    test_accuracy = accuracy_score(test_labels, test_preds)
    test_precision, test_recall, test_f1, _ = precision_recall_fscore_support(test_labels, test_preds, average='weighted')
    
    # è·å–è¾¹ç±»å‹é‡è¦æ€§
    edge_importance = best_model.get_edge_importance_weights()
    
    # ä¿å­˜ç»“æœ
    results = {
        'model_type': 'HeteroGNN_LIVABLE_Fusion',
        'best_valid_f1': best_valid_f1,
        'test_accuracy': test_accuracy,
        'test_precision': test_precision,
        'test_recall': test_recall,
        'test_f1': test_f1,
        'edge_type_importance': edge_importance,
        'model_parameters': sum(p.numel() for p in best_model.parameters()),
        'appnp_parameters': {
            'k': 16,
            'alpha': 0.1
        },
        'classification_report': classification_report(test_labels, test_preds, 
                                                    target_names=[f'CWE-{i}' for i in [119, 20, 399, 125, 264, 200, 189, 416, 190, 362, 476, 787, 284, 254]]),
        'confusion_matrix': confusion_matrix(test_labels, test_preds).tolist()
    }
    
    # åˆ›å»ºç»“æœç›®å½•
    results_dir = Path('hetero_livable_fusion_results')
    results_dir.mkdir(exist_ok=True)
    
    # ä¿å­˜ç»“æœ
    with open(results_dir / 'results.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    torch.save(best_model.state_dict(), results_dir / 'best_fusion_model.pth')
    
    with open(results_dir / 'training_history.json', 'w') as f:
        json.dump(training_history, f, indent=2)
    
    logger.info("ğŸ‰ å¼‚æ„GNN + LIVABLEèåˆæ¨¡å‹è®­ç»ƒå®Œæˆ!")
    logger.info(f"ğŸ“Š æµ‹è¯•ç»“æœ:")
    logger.info(f"   - å‡†ç¡®ç‡: {test_accuracy:.4f}")
    logger.info(f"   - F1åˆ†æ•°: {test_f1:.4f}")
    logger.info(f"   - éªŒè¯æœ€ä½³F1: {best_valid_f1:.4f}")
    logger.info(f"ğŸ”— è¾¹ç±»å‹é‡è¦æ€§:")
    edge_names = ['AST', 'CFG', 'DFG', 'CDG']
    for name, weight in zip(edge_names, edge_importance):
        logger.info(f"   - {name}: {weight:.4f}")


if __name__ == "__main__":
    train_hetero_livable_fusion()